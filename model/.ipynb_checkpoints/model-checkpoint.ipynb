{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eef2aca2-28ed-4b8c-8a79-317e033facae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import joblib\n",
    "import json\n",
    "import matplotlib\n",
    "import os\n",
    "import shutil\n",
    "import pywt\n",
    "import pandas as pd\n",
    "from better_bing_image_downloader import downloader\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee3ec171-f5eb-42a5-bb68-ac8dc90bc48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Images from kaggle\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('./opencv/haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "eye_cascade = cv2.CascadeClassifier('./opencv/haarcascades/haarcascade_eye.xml')\n",
    "\n",
    "def get_cropped_face_if_valid(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(img_gray, 1.1, 2)\n",
    "    if len(faces) != 0:\n",
    "        (x,y,w,h) = faces[0]\n",
    "        cropped_face = img_gray[y:y+h, x:x+w]\n",
    "        return cropped_face\n",
    "\n",
    "path_to_images = './Images/'\n",
    "path_to_cropped_images = './Images/cropped/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa862b4d-0ac1-4b8e-904a-ee7ef6c53f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_paths = []\n",
    "for type in os.scandir(path_to_images):\n",
    "    if type.is_dir():\n",
    "        img_paths.append(type.path)\n",
    "if os.path.exists(path_to_cropped_images):\n",
    "    shutil.rmtree(path_to_cropped_images)\n",
    "os.mkdir(path_to_cropped_images)\n",
    "\n",
    "cropped_img_paths = []\n",
    "emotions_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "793d4ebb-aca6-416d-8d4d-5b8d8e6d44da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in img_paths:\n",
    "    emotions_name = path.split('/')[-1]\n",
    "    emotions_dict[emotions_name] = []\n",
    "    count = 1\n",
    "    for img in os.scandir(path):\n",
    "        cropped = get_cropped_face_if_valid(img.path)\n",
    "        if cropped is not None:\n",
    "            cropped_folder = path_to_cropped_images + emotions_name\n",
    "            if not os.path.exists(cropped_folder):\n",
    "                os.makedirs(cropped_folder)\n",
    "                cropped_img_paths.append(cropped_folder)\n",
    "            \n",
    "            cropped_image_name = emotions_name + str(count) + \".jpg\"\n",
    "            cropped_image_path = cropped_folder + \"/\" + cropped_image_name\n",
    "            cv2.imwrite(cropped_image_path, cropped)\n",
    "            emotions_dict[emotions_name].append(cropped_image_path)\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a6a08fc-1c05-4d71-addc-f321c3779a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From stackoverflow\n",
    "def w2d(img, mode='haar', level=1):\n",
    "    imArray = img\n",
    "    #Datatype conversions\n",
    "    #Convert to grayscale\n",
    "    imArray = cv2.cvtColor(imArray, cv2.COLOR_RGB2GRAY)\n",
    "    #Convert to float\n",
    "    imArray = np.float32(imArray)\n",
    "    imArray /= 255\n",
    "    #Compute coefficients\n",
    "    coeffs = pywt.wavedec2(imArray, mode, level=level)\n",
    "\n",
    "    #Process Coefficients\n",
    "    coeffs_H = list(coeffs)\n",
    "    coeffs_H[0] *= 0\n",
    "\n",
    "    #Reconstruction\n",
    "    imArray_H = pywt.waverec2(coeffs_H, mode)\n",
    "    imArray_H *= 255\n",
    "    imArray_H = np.uint8(imArray_H)\n",
    "\n",
    "    return imArray_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa2ef293-ce8b-4987-91bc-15bc6c50f44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_numbering = {}\n",
    "count = 0\n",
    "for emotion in emotions_dict.keys():\n",
    "    emotions_numbering[emotion] = count\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd93918e-1142-41c9-8a59-83891f09dd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lowni\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pywt\\_multilevel.py:43: UserWarning: Level value of 5 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "x=[] \n",
    "y=[]\n",
    "\n",
    "for emotion, image_path in emotions_dict.items():\n",
    "    for image in image_path:\n",
    "        img = cv2.imread(image)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img_scale = cv2.resize(img, (32,32))\n",
    "        img_w2d = w2d(img, 'db1',5)\n",
    "        img_w2d_scale = cv2.resize(img_w2d, (32,32))\n",
    "        combined_img = np.vstack((img_scale.reshape(32*32*3,1), img_w2d_scale.reshape(32*32,1)))\n",
    "        x.append(combined_img)\n",
    "        y.append(emotions_numbering[emotion])\n",
    "X = np.array(x).reshape(len(x),4096).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6db8eb-6c82-4d98-8287-9cfc8f4e98ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "pipe = Pipeline([('scalar', StandardScaler()), ('svc', SVC(kernel = 'rbf',C=10))])\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d321779-b8ef-4ec5-b69a-bdb759834af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2b0f68-dd34-4ce6-a935-6eec01d2f478",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'svm': {\n",
    "        'model': svm.SVC(gamma='auto',probability=True),\n",
    "        'params': {\n",
    "            'svc__C': [1,10,100,1000],\n",
    "            'svc__kernel': ['rbf', 'linear']\n",
    "        }\n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'randomforestclassifier__n_estimators': [1,5,10]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression': {\n",
    "        'model': LogisticRegression(solver='liblinear', multi_class='auto'),\n",
    "        'params': {\n",
    "            'logisticregression__C': [1,5,10]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "scores =[]\n",
    "best_estimators = {}\n",
    "for algo, mp in model_params.items():\n",
    "    print(algo)\n",
    "    pipe = make_pipeline(StandardScaler(), mp['model'])\n",
    "    clf = GridSearchCV(pipe, mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(X_train,y_train)\n",
    "    scores.append({\n",
    "        'model':algo,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n",
    "    best_estimators[algo] = clf.best_estimator_\n",
    "\n",
    "df = pd.DataFrame(scores, columns = ['model', 'best_score', 'best_params'])\n",
    "print(df[['model']])\n",
    "print(df[['best_score']])\n",
    "print(df[['best_params']])\n",
    "\n",
    "print(best_estimators['svm'].score(X_test,y_test))\n",
    "print(best_estimators['random_forest'].score(X_test,y_test))\n",
    "print(best_estimators['logistic_regression'].score(X_test,y_test))\n",
    "best_clf = best_estimators['svm']\n",
    "cm = confusion_matrix(y_test, best_clf.predict(X_test))\n",
    "print(cm)\n",
    "best_clf = best_estimators['svm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2769d641-e623-4ebe-a319-a9d68b3aed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'svm': {\n",
    "        'model': svm.SVC(gamma='auto',probability=True),\n",
    "        'params': {\n",
    "            'svc__C': [1,10,100,1000],\n",
    "            'svc__kernel': ['rbf', 'linear']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "scores =[]\n",
    "best_estimators = {}\n",
    "for algo, mp in model_params.items():\n",
    "    print(algo)\n",
    "    pipe = make_pipeline(StandardScaler(), mp['model'])\n",
    "    clf = GridSearchCV(pipe, mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(X_train,y_train)\n",
    "    scores.append({\n",
    "        'model':algo,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n",
    "    best_estimators[algo] = clf.best_estimator_\n",
    "\n",
    "best_clf = best_estimators['svm']\n",
    "#Save the model\n",
    "joblib.dump(best_clf, 'saved_model.pkl')\n",
    "\n",
    "#Save emotion dictionary\n",
    "with open(\"class_dictionary.json\",\"w\") as f:\n",
    "    f.write(json.dumps(emotions_numbering))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10737e71-bbfb-479a-8283-23176560b7d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dec405-54ff-489e-af9c-ada235e5457f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29983d9f-0436-43e0-84ac-b758eaed3afd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53de9d43-01d8-4dfa-bb20-63aa6bfeffe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
